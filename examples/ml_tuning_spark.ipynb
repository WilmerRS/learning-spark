{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93f9ec7-f466-4153-84c4-f4bc2266c474",
   "metadata": {},
   "source": [
    "# **ðŸš€ Machine Learning Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fddab15-15fa-493f-9776-c63872b6a9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/12 19:56:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"linear-regression-spark\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795fc696-dcce-4b34-bfe6-917751e913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark.createDataFrame(\n",
    "    [\n",
    "        (0, \"a b c d e spark\", 1.0),\n",
    "        (1, \"b d\", 0.0),\n",
    "        (2, \"spark f g h\", 1.0),\n",
    "        (3, \"hadoop mapreduce\", 0.0),\n",
    "        (4, \"b spark who\", 1.0),\n",
    "        (5, \"g d a y\", 0.0),\n",
    "        (6, \"spark fly\", 1.0),\n",
    "        (7, \"was mapreduce\", 0.0),\n",
    "        (8, \"e spark program\", 1.0),\n",
    "        (9, \"a e c l\", 0.0),\n",
    "        (10, \"spark compile\", 1.0),\n",
    "        (11, \"hadoop software\", 0.0)\n",
    "    ], \n",
    "    [\"id\", \"text\", \"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c2d273e-64fd-4af0-aef7-412ac6b5418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-----+\n",
      "| id|           text|label|\n",
      "+---+---------------+-----+\n",
      "|  0|a b c d e spark|  1.0|\n",
      "|  1|            b d|  0.0|\n",
      "+---+---------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3c98e2-52b1-41fc-a261-69cef5cc7549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(\n",
    "    inputCol=\"text\", \n",
    "    outputCol=\"words\",\n",
    ")\n",
    "hashingTF = HashingTF(\n",
    "    inputCol=tokenizer.getOutputCol(), \n",
    "    outputCol=\"features\",\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        tokenizer, \n",
    "        hashingTF, \n",
    "        lr,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b3db45b-bed4-49c1-b5e1-a43b6538b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-----+--------------------+\n",
      "| id|           text|label|               words|\n",
      "+---+---------------+-----+--------------------+\n",
      "|  0|a b c d e spark|  1.0|[a, b, c, d, e, s...|\n",
      "|  1|            b d|  0.0|              [b, d]|\n",
      "+---+---------------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+---------------+-----+--------------------+--------------------+\n",
      "| id|           text|label|               words|            features|\n",
      "+---+---------------+-----+--------------------+--------------------+\n",
      "|  0|a b c d e spark|  1.0|[a, b, c, d, e, s...|(262144,[74920,89...|\n",
      "|  1|            b d|  0.0|              [b, d]|(262144,[89530,14...|\n",
      "+---+---------------+-----+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = tokenizer.transform(training)\n",
    "words.show(2)\n",
    "\n",
    "hashingTF.transform(words).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83526c46-8228-4b00-99e2-f1ff958300e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# This will allow us to jointly choose parameters for all Pipeline stages.\n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,\n",
    "# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "407248c3-eb79-4efd-a047-78124039b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/12 12:37:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/12/12 12:37:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=BinaryClassificationEvaluator(),\n",
    "    numFolds=3,\n",
    ")\n",
    "\n",
    "cvModel = crossval.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46882ccf-b699-414f-9e8a-89e44ddc465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=4, text='spark i j k', probability=DenseVector([0.3413, 0.6587]), prediction=1.0)\n",
      "Row(id=5, text='l m n', probability=DenseVector([0.9438, 0.0562]), prediction=0.0)\n",
      "Row(id=6, text='mapreduce spark', probability=DenseVector([0.3451, 0.6549]), prediction=1.0)\n",
      "Row(id=7, text='apache hadoop', probability=DenseVector([0.9561, 0.0439]), prediction=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Prepare test documents, which are unlabeled.\n",
    "test = spark.createDataFrame(\n",
    "    [\n",
    "        (4, \"spark i j k\"),\n",
    "        (5, \"l m n\"),\n",
    "        (6, \"mapreduce spark\"),\n",
    "        (7, \"apache hadoop\"),\n",
    "    ], \n",
    "    [\"id\", \"text\"]\n",
    ")\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ed7d28-6e50-4640-8639-f660f63a16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
